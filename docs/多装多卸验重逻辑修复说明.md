# 多装多卸验重逻辑修复说明

## 问题描述

在实现多装多卸功能后，原有的验重逻辑存在以下问题：

### 1. 精确字符串匹配问题
- **地点顺序敏感**：`北京|上海` 和 `上海|北京` 被认为是不同的记录
- **地点数量敏感**：`北京|上海` 和 `北京|上海|广州` 被认为是不同的记录
- **重复地点敏感**：`北京|北京|上海` 和 `北京|上海` 被认为是不同的记录

### 2. 实际业务场景
- 同一司机同一天从北京和上海装货，运到广州和深圳
- 地点顺序可能不同：`北京|上海` vs `上海|北京`
- 地点数量可能不同：`北京|上海` vs `北京|上海|天津`
- 这些在业务上应该被认为是同一条运单

## 解决方案

### 1. 创建地点集合比较函数

```sql
CREATE OR REPLACE FUNCTION compare_location_arrays(locations1 text, locations2 text)
RETURNS boolean
```

**功能特点**：
- 将地点字符串解析为数组
- 自动去除空值和重复值
- 使用集合比较而非顺序比较
- 支持地点顺序不同的情况

**比较逻辑**：
1. 解析地点字符串：`"北京|上海|广州"` → `["北京", "上海", "广州"]`
2. 清理数组：去除空值和重复值
3. 比较集合：检查两个地点集合是否包含相同的地点

### 2. 更新验重函数

#### preview_import_with_duplicates_check
- 使用 `compare_location_arrays` 函数比较装货地点
- 使用 `compare_location_arrays` 函数比较卸货地点
- 保持其他字段的精确匹配

#### check_logistics_record_duplicate
- 同样使用地点集合比较
- 支持编辑模式下的重复检查

## 修复效果

### 修复前的问题
```sql
-- 这些记录会被认为是不同的（错误）
'北京|上海' ≠ '上海|北京'
'北京|上海' ≠ '北京|上海|广州'
'北京|北京|上海' ≠ '北京|上海'
```

### 修复后的效果
```sql
-- 这些记录现在被认为是相同的（正确）
'北京|上海' = '上海|北京'  -- 地点顺序不同，但集合相同
'北京|上海' ≠ '北京|上海|广州'  -- 地点数量不同，集合不同
'北京|北京|上海' = '北京|上海'  -- 重复地点被自动去重
```

## 测试用例

### 1. 地点集合比较测试
```sql
-- 测试相同地点，不同顺序
SELECT compare_location_arrays('北京|上海|广州', '上海|北京|广州'); -- 返回 true

-- 测试相同地点，不同数量
SELECT compare_location_arrays('北京|上海', '北京|上海|广州'); -- 返回 false

-- 测试包含重复地点
SELECT compare_location_arrays('北京|北京|上海', '北京|上海'); -- 返回 true
```

### 2. 验重逻辑测试
- 导入包含多地点的Excel文件
- 验证相同地点集合的记录被正确识别为重复
- 验证不同地点集合的记录被正确识别为新记录

## 业务影响

### 1. 正面影响
- **提高数据质量**：避免因地点顺序不同导致的重复数据
- **简化用户操作**：用户不需要关心地点输入顺序
- **减少数据冗余**：自动识别业务上相同的运单

### 2. 注意事项
- **地点去重**：重复的地点会被自动去重
- **空值处理**：空地点字符串会被正确处理
- **性能影响**：地点集合比较比字符串比较稍慢，但影响很小

## 兼容性

### 1. 向后兼容
- 现有的单地点数据无需修改
- 新的多地点数据可以正常使用
- 混合使用单地点和多地点数据

### 2. 数据迁移
- 不需要数据迁移
- 现有数据继续使用精确字符串匹配
- 新数据使用集合比较

## 使用建议

### 1. 数据录入
- 可以按任意顺序输入地点
- 重复的地点会被自动去重
- 空地点会被自动过滤

### 2. Excel导入
- 地点格式：`地点1|地点2|地点3`
- 顺序不影响验重结果
- 重复地点会被自动处理

### 3. 数据维护
- 定期检查重复数据
- 使用新的验重逻辑进行数据清理
- 确保地点数据的一致性

## 技术实现

### 1. 核心函数
- `compare_location_arrays()`: 地点集合比较
- `preview_import_with_duplicates_check()`: 导入验重
- `check_logistics_record_duplicate()`: 单条记录验重

### 2. 性能优化
- 使用数组操作进行地点比较
- 避免复杂的字符串操作
- 保持原有的索引结构

### 3. 错误处理
- 空值安全处理
- 格式错误容错
- 详细的错误信息

这个修复确保了多装多卸功能与验重逻辑的完美配合，提高了数据质量和用户体验。
